#!/usr/bin/env python3
"""
02_split_to_md_simple.py - ç®€åŒ–ç‰ˆæ–‡æ¡£æ‹†åˆ†ï¼ˆç”¨äºæµ‹è¯•ï¼‰

åŠŸèƒ½ï¼š
- åˆ›å»ºæ¨¡æ‹Ÿçš„markdownæ–‡ä»¶ç”¨äºæµ‹è¯•æµç¨‹
- ä¸ä¾èµ–äºå¤–éƒ¨å·¥å…·ï¼ˆpandoc, pdftohtmlï¼‰
"""

import json
import os
import sys
from pathlib import Path


def load_config(temp_dir: str) -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_path = os.path.join(temp_dir, "config.json")
    if not os.path.exists(config_path):
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
    
    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def create_mock_markdown_files(temp_dir: str, input_file: str) -> list:
    """åˆ›å»ºæ¨¡æ‹Ÿçš„markdownæ–‡ä»¶ç”¨äºæµ‹è¯•"""
    print(f"ğŸ“„ åˆ›å»ºæ¨¡æ‹Ÿmarkdownæ–‡ä»¶ç”¨äºæµ‹è¯•...")
    
    # åˆ›å»ºimagesç›®å½•
    images_dir = os.path.join(temp_dir, "images")
    os.makedirs(images_dir, exist_ok=True)
    
    # æ ¹æ®è¾“å…¥æ–‡ä»¶ç±»å‹åˆ›å»ºä¸åŒçš„å†…å®¹
    file_ext = Path(input_file).suffix.lower()
    
    if "paper" in Path(input_file).stem.lower():
        # å­¦æœ¯è®ºæ–‡å†…å®¹
        pages_content = [
            """# A Study of Machine Learning Applications in Natural Language Processing

## Abstract

This paper presents a comprehensive review of machine learning applications in natural language processing (NLP). We examine various techniques including transformer architectures, attention mechanisms, and their impact on modern AI systems.""",
            
            """## 1. Introduction

Natural Language Processing has evolved dramatically over the past decade. The introduction of deep learning methods has revolutionized how machines understand and generate human language.

### 1.1 Background

Machine learning, particularly deep learning, has become the cornerstone of modern NLP systems.""",
            
            """### 1.2 Scope of Study

This research focuses on three main areas:
- Transformer architectures and their variants
- Attention mechanisms in sequence-to-sequence models
- Pre-trained language models and fine-tuning approaches""",
            
            """## 2. Methodology

Our methodology consists of systematic literature review and experimental validation. We analyzed over 200 research papers published between 2017 and 2024.

### 2.1 Data Collection

The dataset includes:
- Academic papers from major conferences (ACL, EMNLP, NAACL)
- Industry research reports
- Open-source implementations and benchmarks"""
        ]
    else:
        # é€šç”¨æ–‡æ¡£å†…å®¹
        pages_content = [
            """# Document Title

This is the first page of the document. It contains important information about the topic being discussed.""",
            
            """## Chapter 1: Introduction

This chapter introduces the main concepts and provides background information necessary to understand the content.""",
            
            """## Chapter 2: Main Content

Here we dive into the detailed discussion of the primary topics covered in this document.""",
            
            """## Conclusion

This section summarizes the key points and provides final thoughts on the subject matter."""
        ]
    
    md_files = []
    for i, content in enumerate(pages_content):
        page_num = f"{i+1:04d}"
        md_file = os.path.join(temp_dir, f"page{page_num}.md")
        
        with open(md_file, 'w', encoding='utf-8') as f:
            f.write(content)
        
        md_files.append(md_file)
        print(f"ğŸ“ åˆ›å»º: page{page_num}.md")
    
    print(f"âœ… æ¨¡æ‹Ÿæ–‡æ¡£æ‹†åˆ†å®Œæˆï¼Œå…± {len(md_files)} ä¸ªæ–‡ä»¶")
    return md_files


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) != 2:
        print("ç”¨æ³•: python 02_split_to_md_simple.py <temp_dir>")
        return 1
    
    temp_dir = sys.argv[1]
    
    try:
        # åŠ è½½é…ç½®
        config = load_config(temp_dir)
        
        # åˆ›å»ºæ¨¡æ‹Ÿmarkdownæ–‡ä»¶
        md_files = create_mock_markdown_files(temp_dir, config['input_file'])
        
        # æ›´æ–°é…ç½®
        config['md_files'] = md_files
        config_path = os.path.join(temp_dir, "config.json")
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ¯ æ‹†åˆ†å®Œæˆ: {len(md_files)} ä¸ªæ–‡ä»¶")
        return 0
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())